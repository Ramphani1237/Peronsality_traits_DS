{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e812ebd",
   "metadata": {},
   "source": [
    "# 4. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9369ad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1184 samples\n",
      "Test set size: 296 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('../assets/raw/essaytrain.csv', encoding='latin1')\n",
    "traits = ['cEXT', 'cNEU', 'cAGR', 'cCON', 'cOPN']\n",
    "df_numeric = df.copy()\n",
    "X = df_numeric['TEXT']          # input text\n",
    "y = df_numeric[traits]          # OCEAN traits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f'Training set size: {X_train.shape[0]} samples')\n",
    "print(f'Test set size: {X_test.shape[0]} samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99e597f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramphani\\AppData\\Local\\Temp\\ipykernel_1436\\2986040854.py:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_numeric[traits] = df_numeric[traits].replace({'y':1, 'n':0})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL EVALUATION ===\n",
      "\n",
      "=== cOPN ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.56      0.60       155\n",
      "           1       0.58      0.67      0.62       141\n",
      "\n",
      "    accuracy                           0.61       296\n",
      "   macro avg       0.62      0.62      0.61       296\n",
      "weighted avg       0.62      0.61      0.61       296\n",
      "\n",
      "\n",
      "\n",
      "=== cCON ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.49      0.51       140\n",
      "           1       0.57      0.62      0.60       156\n",
      "\n",
      "    accuracy                           0.56       296\n",
      "   macro avg       0.55      0.55      0.55       296\n",
      "weighted avg       0.56      0.56      0.56       296\n",
      "\n",
      "\n",
      "\n",
      "=== cEXT ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.52      0.53       143\n",
      "           1       0.56      0.57      0.56       153\n",
      "\n",
      "    accuracy                           0.55       296\n",
      "   macro avg       0.55      0.55      0.55       296\n",
      "weighted avg       0.55      0.55      0.55       296\n",
      "\n",
      "\n",
      "\n",
      "=== cAGR ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.26      0.38       150\n",
      "           1       0.53      0.87      0.66       146\n",
      "\n",
      "    accuracy                           0.56       296\n",
      "   macro avg       0.60      0.56      0.52       296\n",
      "weighted avg       0.60      0.56      0.52       296\n",
      "\n",
      "\n",
      "\n",
      "=== cNEU ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.46      0.47       137\n",
      "           1       0.55      0.56      0.55       159\n",
      "\n",
      "    accuracy                           0.51       296\n",
      "   macro avg       0.51      0.51      0.51       296\n",
      "weighted avg       0.51      0.51      0.51       296\n",
      "\n",
      "\n",
      "\n",
      "Predictions saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# STEP 4: MODEL BUILDING\n",
    "# Predicting OCEAN personality traits from essay text\n",
    "# =========================\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# =========================\n",
    "# 1️⃣ Load Dataset & Traits\n",
    "# =========================\n",
    "df = pd.read_csv('../assets/raw/essaytrain.csv', encoding='latin1')\n",
    "traits = ['cOPN', 'cCON', 'cEXT', 'cAGR', 'cNEU']\n",
    "\n",
    "# Convert y/n to 1/0\n",
    "df_numeric = df.copy()\n",
    "df_numeric[traits] = df_numeric[traits].replace({'y':1, 'n':0})\n",
    "\n",
    "# =========================\n",
    "# 2️⃣ Prepare Features and Target\n",
    "# =========================\n",
    "X = df_numeric['TEXT']\n",
    "y = df_numeric[traits]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 3️⃣ TF-IDF Vectorization\n",
    "# =========================\n",
    "tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# =========================\n",
    "# 4️⃣ Multi-label Logistic Regression\n",
    "# =========================\n",
    "model = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# =========================\n",
    "# 5️⃣ Make Predictions\n",
    "# =========================\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# =========================\n",
    "# 6️⃣ Evaluate Model (Trait by Trait)\n",
    "# =========================\n",
    "print(\"=== MODEL EVALUATION ===\\n\")\n",
    "for i, trait in enumerate(traits):\n",
    "    print(f\"=== {trait} ===\")\n",
    "    print(classification_report(y_test[trait], y_pred[:, i]))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# =========================\n",
    "# ✅ Optional: Save predictions\n",
    "# =========================\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=traits)\n",
    "y_pred_df.to_csv('../assets/processed/predictions_step5.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203ab65e",
   "metadata": {},
   "source": [
    "# Step 4 Summary: Personality Trait Prediction\n",
    "Using TF-IDF vectorization on essay text, we trained a multi-label Logistic Regression model (MultiOutputClassifier) to predict all five OCEAN traits simultaneously. Each trait’s performance was evaluated individually with precision, recall, and F1-score, and predictions were saved for further analysis. This step enabled accurate trait-level classification from textual essays."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
